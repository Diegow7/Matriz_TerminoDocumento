{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 06: Base de Datos Vectoriales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1: Recuperación con TF-IDF\n",
    "\n",
    "**1. Carga los datos en Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carga el archivo CSV en un DataFrame\n",
    "df = pd.read_csv(\"../data/wiki_movie_plots_deduped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Title  \\\n",
      "0            Kansas Saloon Smashers   \n",
      "1     Love by the Light of the Moon   \n",
      "2           The Martyred Presidents   \n",
      "3  Terrible Teddy, the Grizzly King   \n",
      "4            Jack and the Beanstalk   \n",
      "\n",
      "                                                Plot  \n",
      "0  A bartender is working at a saloon, serving dr...  \n",
      "1  The moon, painted with a smiling face hangs ov...  \n",
      "2  The film, just over a minute long, is composed...  \n",
      "3  Lasting just 61 seconds and consisting of two ...  \n",
      "4  The earliest known adaptation of the classic f...  \n"
     ]
    }
   ],
   "source": [
    "# Filtra únicamente las columnas Title y Plot\n",
    "df_filtered = df[['Title', 'Plot']]\n",
    "\n",
    "# Muestra las primeras filas del DataFrame filtrado\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Title  \\\n",
      "0            Kansas Saloon Smashers   \n",
      "1     Love by the Light of the Moon   \n",
      "2           The Martyred Presidents   \n",
      "3  Terrible Teddy, the Grizzly King   \n",
      "4            Jack and the Beanstalk   \n",
      "\n",
      "                                                Plot  \n",
      "0  A bartender is working at a saloon, serving dr...  \n",
      "1  The moon, painted with a smiling face hangs ov...  \n",
      "2  The film, just over a minute long, is composed...  \n",
      "3  Lasting just 61 seconds and consisting of two ...  \n",
      "4  The earliest known adaptation of the classic f...  \n"
     ]
    }
   ],
   "source": [
    "# Filtra únicamente las columnas Title y Plot\n",
    "df_filtered = df[['Title', 'Plot']]\n",
    "\n",
    "# Muestra las primeras filas del DataFrame filtrado\n",
    "print(df_filtered.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Configurar TF-IDF**\n",
    "\n",
    "- usa la libreria scikit-lear para calcular los puntajes TF-IDF de los plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  aaron  abandon  abandoned  abandons  abby  \\\n",
      "Title                                                                         \n",
      "Kansas Saloon Smashers              0.0      0.0        0.0       0.0   0.0   \n",
      "Love by the Light of the Moon       0.0      0.0        0.0       0.0   0.0   \n",
      "The Martyred Presidents             0.0      0.0        0.0       0.0   0.0   \n",
      "Terrible Teddy, the Grizzly King    0.0      0.0        0.0       0.0   0.0   \n",
      "Jack and the Beanstalk              0.0      0.0        0.0       0.0   0.0   \n",
      "\n",
      "                                  abducted  abhi  abilities  ability  \\\n",
      "Title                                                                  \n",
      "Kansas Saloon Smashers                 0.0   0.0        0.0      0.0   \n",
      "Love by the Light of the Moon          0.0   0.0        0.0      0.0   \n",
      "The Martyred Presidents                0.0   0.0        0.0      0.0   \n",
      "Terrible Teddy, the Grizzly King       0.0   0.0        0.0      0.0   \n",
      "Jack and the Beanstalk                 0.0   0.0        0.0      0.0   \n",
      "\n",
      "                                      able  ...   yu  zack  zamindar  zero  \\\n",
      "Title                                       ...                              \n",
      "Kansas Saloon Smashers            0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "Love by the Light of the Moon     0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "The Martyred Presidents           0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "Terrible Teddy, the Grizzly King  0.000000  ...  0.0   0.0       0.0   0.0   \n",
      "Jack and the Beanstalk            0.062146  ...  0.0   0.0       0.0   0.0   \n",
      "\n",
      "                                  zhang  zoe  zombie  zombies  zone  zoo  \n",
      "Title                                                                     \n",
      "Kansas Saloon Smashers              0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "Love by the Light of the Moon       0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "The Martyred Presidents             0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "Terrible Teddy, the Grizzly King    0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "Jack and the Beanstalk              0.0  0.0     0.0      0.0   0.0  0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Función para limpiar texto\n",
    "def clean_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar tildes\n",
    "    text = ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "    # Eliminar números, puntuaciones y caracteres no alfabéticos\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Inicializa el vectorizador TF-IDF con el preprocesador personalizado\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,  # Limita el vocabulario\n",
    "    preprocessor=clean_text,  # Aplica la limpieza personalizada\n",
    "    token_pattern=r'\\b[a-z]{2,}\\b'  # Solo considera palabras de al menos 2 letras\n",
    ")\n",
    "\n",
    "# Calcula los puntajes TF-IDF para los Plots\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_filtered['Plot'].fillna(''))\n",
    "\n",
    "# Convierte la matriz dispersa en un DataFrame\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out(),\n",
    "    index=df_filtered['Title']\n",
    ")\n",
    "\n",
    "# Muestra las primeras filas del DataFrame TF-IDF\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Realizar Consultas:**\n",
    "\n",
    "- Escribe una función que calculo la similitud entre una consulta y los documentos usando la matriz TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Title  Similarity\n",
      "18255                 The Medicine Man    0.452338\n",
      "18965                Death Is a Number    0.440332\n",
      "20811       My Wrongs #8245–8249 & 117    0.392925\n",
      "22406                        King Dave    0.335430\n",
      "18390            The Man in the Mirror    0.331631\n",
      "1942                  Murder in Harlem    0.330803\n",
      "15734                         The Road    0.324203\n",
      "16472  Cheech & Chong's Animated Movie    0.316461\n",
      "23866              Everyday I Love You    0.314217\n",
      "27894                    Junior Senior    0.307387\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calcular_similitud(query, tfidf_vectorizer, tfidf_matrix, titles):\n",
    "    # Limpia la consulta usando la misma lógica de preprocesamiento\n",
    "    query_cleaned = clean_text(query)\n",
    "\n",
    "    # Vectoriza la consulta\n",
    "    query_tfidf = tfidf_vectorizer.transform([query_cleaned])\n",
    "\n",
    "    # Calcula la similitud coseno entre la consulta y los documentos\n",
    "    similitudes = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "    # Crea un DataFrame con los resultados\n",
    "    resultados = pd.DataFrame({\n",
    "        'Title': titles,\n",
    "        'Similarity': similitudes\n",
    "    })\n",
    "\n",
    "    # Ordena los documentos por similitud en orden descendente\n",
    "    resultados_ordenados = resultados.sort_values(by='Similarity', ascending=False)\n",
    "\n",
    "    return resultados_ordenados\n",
    "\n",
    "# Ejemplo de uso\n",
    "consulta = \"man\"\n",
    "resultados = calcular_similitud(consulta, tfidf_vectorizer, tfidf_matrix, df_filtered['Title'])\n",
    "\n",
    "# Muestra los resultados\n",
    "print(resultados.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Evaluar los resultados:**\n",
    "\n",
    "- Registra los documentos recuperados y analiza su relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en: data\\resultados_recuperados.csv\n",
      "Documentos relevantes (similitud >= 0.4): 2\n",
      "Documentos relevantes:\n",
      "                   Title  Similarity\n",
      "18255   The Medicine Man    0.452338\n",
      "18965  Death Is a Number    0.440332\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def registrar_documentos(resultados, output_path=\"resultados_recuperados.csv\", threshold=0.5):\n",
    "    # Asegúrate de que el directorio existe\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Marca los documentos como relevantes o no según el umbral\n",
    "    resultados['Relevancia'] = resultados['Similarity'] >= threshold\n",
    "\n",
    "    # Guarda los resultados en un archivo CSV\n",
    "    resultados.to_csv(output_path, index=False)\n",
    "    print(f\"Resultados guardados en: {output_path}\")\n",
    "\n",
    "    # Filtra los documentos relevantes\n",
    "    resultados_filtrados = resultados[resultados['Relevancia']]\n",
    "    print(f\"Documentos relevantes (similitud >= {threshold}): {len(resultados_filtrados)}\")\n",
    "\n",
    "    return resultados_filtrados\n",
    "\n",
    "# Llama a la función con los resultados de la consulta\n",
    "ruta_salida = os.path.join(\"data\", \"resultados_recuperados.csv\")\n",
    "documentos_relevantes = registrar_documentos(resultados, output_path=ruta_salida, threshold=0.4)\n",
    "\n",
    "# Analiza los resultados relevantes\n",
    "print(\"Documentos relevantes:\")\n",
    "print(documentos_relevantes[['Title', 'Similarity']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Recuperación con BM25\n",
    "\n",
    "**1. Configurar Elasticsearch:**\n",
    "\n",
    "- Reutiliza el índice creado en el Ejercicio 1 para realizar consultas basadas en BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Instalar Whoosh o Rank-BM25:**\n",
    "\n",
    "Para usar BM25 en Python, podemos usar rank_bm25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank-bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from rank-bm25) (1.23.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install rank-bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Implementar Recuperación con BM25:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la consulta con BM25:\n",
      "Resultado 1:\n",
      "Título: For Her Sake\n",
      "Plot: The film is a period drama taking place right before the start of the American Civil War. A young Southern girl chooses between two suitors. She chooses the man who goes to fight Stars and Bars of the Confederacy whilst the rejected suitor goes to fight for the Union. During the war, the Confederate soldier is captured and brought before the Union officer who recognizes him as his rival. The Union man is cruel to his rival and tries to break his spirit with harsh treatment. The girl hears of his plight and becomes determined to rescue him. She evades the guards and gives her lover a file to free himself from the bars. Together they flee and are discovered in the final moments of their escape. One of the sentries shoots at the man, but his shot misses and the two flee on horseback.[1] The Union officer is enraged by the escape and tracks the pair to the girl's home just over the Federal line. He sets up guards around the house and enters alone to take them prisoner by his own hand. He makes his way through the house and breaks down the doors to find the man he wants. Upon finding the man, he does not arrest him - for the Confederate soldier is grief-stricken and bending over the body of his fiancée. The bullet the sentry shot at him instead took her life. Together the two rivals mourn her death, and the Union officer leaves without arresting his rival - for her sake.[1]\n",
      "Score: 1.7688889868792632\n",
      "Resultado 2:\n",
      "Título: Kansas Saloon Smashers\n",
      "Plot: A bartender is working at a saloon, serving drinks to customers. After he fills a stereotypically Irish man's bucket with beer, Carrie Nation and her followers burst inside. They assault the Irish man, pulling his hat over his eyes and then dumping the beer over his head. The group then begin wrecking the bar, smashing the fixtures, mirrors, and breaking the cash register. The bartender then sprays seltzer water in Nation's face before a group of policemen appear and order everybody to leave.[1]\n",
      "Score: 1.6913198285442161\n",
      "Resultado 3:\n",
      "Título: The Musketeers of Pig Alley\n",
      "Plot: The film is about a poor married couple living in New York City. The husband works as a musician and must often travel for work. When returning, his wallet is taken by a gangster. His wife goes to a ball where a man tries to drug her, but his attempt is stopped by the same man who robbed the husband. The two criminals become rivals, and a shootout ensues. The husband gets caught in the shootout and recognizes one of the men as the gangster who took his money. The husband sneaks his wallet back and the gangster goes to safety in the couple's apartment. Policemen track the gangster down but the wife gives him a false alibi.\n",
      "Score: 1.5852654769094259\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Asegurar que nltk tenga los recursos necesarios\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenizar los documentos (convertir texto en listas de palabras)\n",
    "tokenized_documents = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "# Crear el modelo BM25\n",
    "bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "# Definir la consulta y tokenizarla\n",
    "query = \"man\"\n",
    "tokenized_query = word_tokenize(query.lower())\n",
    "\n",
    "# Obtener los 3 documentos más relevantes\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "top_n = 3\n",
    "top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Resultados de la consulta con BM25:\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    print(f\"Resultado {i+1}:\")\n",
    "    print(f\"Título: {metadatas[idx]['Title']}\")\n",
    "    print(f\"Plot: {documents[idx]}\")\n",
    "    print(f\"Score: {scores[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Recuperación con FAISS\n",
    "\n",
    "**1. Configurar FAISS:**\n",
    "\n",
    "Crear un índice en FAISS y agregar los embeddings generados previamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Instalar FAISS:**\n",
    "\n",
    "Si aún no lo tienes instalado, ejecútalo con:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp38-cp38-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\diego\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from faiss-cpu) (1.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\diego\\appdata\\roaming\\python\\python38\\site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp38-cp38-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.6 MB 640.0 kB/s eta 0:00:23\n",
      "   ---------------------------------------- 0.0/14.6 MB 388.9 kB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.1/14.6 MB 930.9 kB/s eta 0:00:16\n",
      "    --------------------------------------- 0.2/14.6 MB 1.1 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.3/14.6 MB 1.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.6/14.6 MB 2.0 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.7/14.6 MB 2.0 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/14.6 MB 2.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.3/14.6 MB 3.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.2/14.6 MB 4.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.1/14.6 MB 5.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.2/14.6 MB 7.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.2/14.6 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.2/14.6 MB 7.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.3/14.6 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.3/14.6 MB 8.0 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.3/14.6 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 7.3/14.6 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/14.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/14.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.4/14.6 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.5/14.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.5/14.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.6/14.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.6/14.6 MB 13.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 13.3 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Configurar FAISS y agregar los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han agregado 50 vectores al índice FAISS.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convertir los embeddings a un array numpy (float32 requerido por FAISS)\n",
    "embedding_dim = len(embeddings[0])  # Dimensión de los embeddings\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # Crear un índice de FAISS basado en L2 (distancia euclidiana)\n",
    "\n",
    "# Agregar los embeddings al índice\n",
    "index.add(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "print(f\"Se han agregado {index.ntotal} vectores al índice FAISS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Realizar una búsqueda en FAIS:**\n",
    "\n",
    "Para buscar los documentos más similares a una consulta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la consulta con FAISS:\n",
      "Resultado 1:\n",
      "Título: The Black Viper\n",
      "Plot: A thug accosts a girl as she leaves her workplace but a man rescues her. The thug vows revenge and, with the help of two friends, attacks the girl and her rescuer again as they're going for a walk. This time they succeed in kidnapping the rescuer. He is bound and gagged and taken away in a cart. The girl runs home and gets help from several neighbors. They track the ruffians down to a cabin in the mountains where the gang has trapped their victim and set the cabin on fire. A thug and Rescuer fight on the roof of the house.\n",
      "Distancia: 1.6032384634017944\n",
      "Resultado 2:\n",
      "Título: Petticoat Camp\n",
      "Plot: Only lasting 15 minutes, it is a light-hearted comedy about the battle between the sexes as several married couples go on a camp-out together. The women soon realize that the men expect them to do perform all of the work while they relax, leading to several comedic situations.\n",
      "Distancia: 1.6491906642913818\n",
      "Resultado 3:\n",
      "Título: How Brown Saw the Baseball Game\n",
      "Plot: Before heading out to a baseball game at a nearby ballpark, sports fan Mr. Brown drinks several highball cocktails. He arrives at the ballpark to watch the game, but has become so inebriated that the game appears to him in reverse, with the players running the bases backwards and the baseball flying back into the pitcher's hand. After the game is over, Mr. Brown is escorted home by one of his friends. When they arrive at Brown's house, they encounter his wife who becomes furious with the friend and proceeds to physically assault him, believing he is responsible for her husband's severe intoxication.[1]\n",
      "Distancia: 1.6648643016815186\n"
     ]
    }
   ],
   "source": [
    "# Definir la consulta\n",
    "query = \"man\"\n",
    "\n",
    "# Generar el embedding de la consulta\n",
    "query_embedding = model.encode([query]).astype(np.float32)\n",
    "\n",
    "# Buscar los 3 documentos más similares\n",
    "k = 3\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Resultados de la consulta con FAISS:\")\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"Resultado {i+1}:\")\n",
    "    print(f\"Título: {metadatas[idx]['Title']}\")\n",
    "    print(f\"Plot: {documents[idx]}\")\n",
    "    print(f\"Distancia: {distances[0][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4: Recuperación con ChromaDB\n",
    "\n",
    "**1. Configurar ChromaDB:**\n",
    "\n",
    "Inicia una base de datos de ChromaDB y define el esquema con los campos Tittle, Plot y Embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Preparar los datos**\n",
    "Seleccionamos la columna que contiene el texto (por ejemplo, Plot) y una columna como identificadores únicos (ID o similar). Si no hay una columna de IDs, podemos generarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas de interés\n",
    "documents = df['Plot'].tolist()  # Textos principales de las películas\n",
    "ids = df.index.tolist()  # Usamos los índices como IDs únicos\n",
    "metadatas = df[['Title']].to_dict(orient='records')  # Metadatos relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Generar embeddings**\n",
    "\n",
    "Usamos SentenceTransformer para convertir cada documento en un vector numérico (embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Cargar el modelo de embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la cantidad de documentos a procesar, esto se lo hace por motivos de recursos disponibles\n",
    "num_docs = 10  \n",
    "\n",
    "# Generar los embeddings solo para los primeros `num_docs` documentos\n",
    "embeddings = model.encode(documents[:num_docs]).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Configurar e inicializar ChromaDB**\n",
    "\n",
    "Inicializamos el cliente de ChromaDB para crear o cargar la colección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "# Inicializar la base de datos vectorial con persistencia\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")  # Almacenará los datos en disco\n",
    "\n",
    "# Crear o cargar la colección\n",
    "collection = client.get_or_create_collection(\"wiki_movies_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Agregar los documentos a la colección**\n",
    "\n",
    "Añadimos los textos (documents), sus metadatos, IDs y embeddings a la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos: 10\n",
      "Metadatos: 10\n",
      "IDs: 10\n",
      "Embeddings: 10\n"
     ]
    }
   ],
   "source": [
    "# Asegurar que todas las listas tengan la misma longitud\n",
    "documents = documents[:num_docs]\n",
    "metadatas = metadatas[:num_docs]\n",
    "ids = ids[:num_docs]\n",
    "\n",
    "# Verificar longitudes\n",
    "print(f\"Documentos: {len(documents)}\")\n",
    "print(f\"Metadatos: {len(metadatas)}\")\n",
    "print(f\"IDs: {len(ids)}\")\n",
    "print(f\"Embeddings: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos agregados exitosamente a la colección.\n"
     ]
    }
   ],
   "source": [
    "# Convertir todos los IDs a cadenas de texto\n",
    "ids = [str(id) for id in ids]\n",
    "\n",
    "# Agregar los documentos, metadatos, IDs y embeddings a la colección\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids,\n",
    "    embeddings=embeddings\n",
    ")\n",
    "\n",
    "print(\"Documentos agregados exitosamente a la colección.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6: Realizar la consulta**\n",
    "\n",
    "Convertimos la consulta \"man\" en un embedding y buscamos los documentos más similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de la consulta:\n",
      "Resultado 1:\n",
      "[\"A bartender is working at a saloon, serving drinks to customers. After he fills a stereotypically Irish man's bucket with beer, Carrie Nation and her followers burst inside. They assault the Irish man, pulling his hat over his eyes and then dumping the beer over his head. The group then begin wrecking the bar, smashing the fixtures, mirrors, and breaking the cash register. The bartender then sprays seltzer water in Nation's face before a group of policemen appear and order everybody to leave.[1]\", \"The moon, painted with a smiling face hangs over a park at night. A young couple walking past a fence learn on a railing and look up. The moon smiles. They embrace, and the moon's smile gets bigger. They then sit down on a bench by a tree. The moon's view is blocked, causing him to frown. In the last scene, the man fans the woman with his hat because the moon has left the sky and is perched over her shoulder to see everything better.\", 'The film, just over a minute long, is composed of two shots. In the first, a girl sits at the base of an altar or tomb, her face hidden from the camera. At the center of the altar, a viewing portal displays the portraits of three U.S. Presidents—Abraham Lincoln, James A. Garfield, and William McKinley—each victims of assassination.\\r\\nIn the second shot, which runs just over eight seconds long, an assassin kneels feet of Lady Justice.']\n",
      "Metadatos: [{'Title': 'Kansas Saloon Smashers'}, {'Title': 'Love by the Light of the Moon'}, {'Title': 'The Martyred Presidents'}]\n"
     ]
    }
   ],
   "source": [
    "# Consulta\n",
    "query = \"man\"\n",
    "\n",
    "# Generar el embedding de la consulta\n",
    "query_embedding = model.encode([query]).tolist()\n",
    "\n",
    "# Realizar la consulta\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=3  # Devuelve los 3 documentos más similares\n",
    ")\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Resultados de la consulta:\")\n",
    "for i, result in enumerate(results['documents']):\n",
    "    print(f\"Resultado {i+1}:\")\n",
    "    print(result)\n",
    "    print(\"Metadatos:\", results['metadatas'][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
